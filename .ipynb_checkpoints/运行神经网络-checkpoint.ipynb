{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals,print_function,division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import librosa\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "\n",
    "print(torch.__version__)\n",
    "device =torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    path='wavDatasets//'\n",
    "    listdir=os.listdir(path)\n",
    "    data={}\n",
    "    for x in listdir:\n",
    "        if 'wav' in x:\n",
    "            y,rate=librosa.load('wavDatasets//'+x,sr=4410)\n",
    "            data[x[0:-4]]=y\n",
    "    return data\n",
    "\n",
    "def getLabel():\n",
    "    df=open('wavDatasets//music_dic.pkl','rb')#注意此处是rb\n",
    "    #此处使用的是load(目标文件)\n",
    "    music_dic=pickle.load(df)\n",
    "    df.close()\n",
    "    label={}\n",
    "    for x in music_dic.keys():\n",
    "        y=music_dic[x]\n",
    "        label[x]=one_hot(y)\n",
    "    return label\n",
    "\n",
    "#得到note和num字典\n",
    "def getDict():\n",
    "    note_dic = {}\n",
    "    note = ['<S>','<E>','C4', 'C4#', 'D4', 'D4#', 'E4', 'F4', 'F4#', 'G4',\n",
    "            'G4#', 'A4', 'A4#', 'B4', 'C5', 'C5#', 'D5', 'D5#',\n",
    "            'E5', 'F5', 'F5#', 'G5', 'G5#', 'A5', 'A5#', 'B5',\n",
    "            'C6', 'C6#', 'D6', 'D6#', 'E6', 'F6', 'F6#', 'G6',\n",
    "            'G6#', 'A6', 'A6#', 'B6', 'C7', 'C7#']\n",
    "\n",
    "    for x in range(len(note)):\n",
    "        if note[x] not in note_dic.keys():\n",
    "            # onehot = np.zeros(len(note))\n",
    "            # onehot[x] = 1\n",
    "            note_dic[note[x]] = x\n",
    "    num_dic=dict(zip(note_dic.values(),note_dic.keys()))\n",
    "\n",
    "    return note_dic,num_dic\n",
    "\n",
    "def one_hot(y):\n",
    "    note_dic = getDict()[0]\n",
    "    note=[]\n",
    "    note.append(note_dic['<S>'])\n",
    "    for x in y:\n",
    "        note.append(note_dic[x])\n",
    "    note.append(note_dic['<E>'])\n",
    "    return note\n",
    "\n",
    "#会调用前面的函数，最后返回训练集的数据\n",
    "#形状为（x_train,y_train)，x_train是训练集音频数据，y_train是训练集数据标签\n",
    "#数据类型均为torch.longtensor\n",
    "def getPair():\n",
    "    x=getData()\n",
    "    y=getLabel()\n",
    "    data=[]\n",
    "    label=[]\n",
    "    for key in x.keys():\n",
    "        a=x[key]\n",
    "        a=list(a)#[random.randint(100,120):random.randint(120,140)]\n",
    "        a=torch.Tensor(a).view(len(a),1).long()\n",
    "        b=torch.Tensor(y[key]).view(len(y[key]),1).long()\n",
    "        data.append(a)\n",
    "        label.append(b)\n",
    "    return data,label\n",
    "\n",
    "\n",
    "\n",
    "#获取数据和字典\n",
    "x_train, y_train = getPair()\n",
    "MAX_LENGTH = max([i.shape[0] for i in x_train])\n",
    "note_dic,num_dic=getDict()#得到字典\n",
    "S_token=0#代表句子的开始\n",
    "E_token=1#代表句子的结束\n",
    "\n",
    "#不要动它\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不要动它\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length=max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat([embedded[0], hidden[0]], 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat([embedded[0], attn_applied[0]], 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "#不要动它\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,maxlen=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(maxlen, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    decoder_input = torch.tensor([[S_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    teacher_forcing_ratio=0.5\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the targer as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Without teaching forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == E_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "#不要动它\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "#不要动它\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs是训练迭代次数\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1, plot_every=1, learning_rate=0.01,epochs=10):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch:',epoch)\n",
    "        for iter in range(1, n_iters + 1):\n",
    "            print('iter:',iter)\n",
    "            input_tensor = x_train[iter-1]\n",
    "            target_tensor = y_train[iter-1]\n",
    "            print('input_tensor:',input_tensor.size())\n",
    "            print('target_tensor:',target_tensor.size())\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#不要动它\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "\n",
    "#不要动它\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[S_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            # print(topi.item())\n",
    "            if topi.item() == E_token:\n",
    "                # print('<E>')\n",
    "                decoded_words.append('<E>')\n",
    "                break\n",
    "            else:\n",
    "                # print(di,num_dic[topi.item()])\n",
    "                decoded_words.append(num_dic[topi.item()])\n",
    "\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "#x_test是测试音频数据\n",
    "#y_test是测试数据标签\n",
    "#n是测试数据的数量\n",
    "def evaluateRandomly(encoder, decoder, x_test,y_test=None,n=1):\n",
    "    for i in range(n):\n",
    "        print('>', x_test[i].size())\n",
    "        print('=', y_test[i].size())\n",
    "        output_words, attentions = evaluate(encoder, decoder, x_test[i])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
